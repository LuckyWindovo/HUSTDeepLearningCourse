import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

import warnings
import logging
import time
from pathlib import Path

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings('ignore')
logging.getLogger().setLevel(logging.ERROR)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from config import Config
from model import get_model
from utils import *

# åˆ é™¤è¿™è¡Œï¼štorch.backends.cudnn.benchmark = True
# ç§»åˆ°mainå‡½æ•°å†…éƒ¨

def run_single_experiment(exp_name, exp_cfg, cfg):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\n{'='*60}")
    print(f"Starting {exp_name}")
    print(f"Config: {exp_cfg}")
    print(f"{'='*60}")
    
    # åˆ›å»ºå®éªŒç›®å½•
    exp_dir = Path(cfg.RESULTS_PATH) / exp_name
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­ï¼ˆä»…åœ¨éœ€è¦å¤ç°æ€§æ—¶ï¼‰
    if cfg.DETERMINISTIC:
        torch.manual_seed(cfg.SEED)
    
    # åŠ è½½æ•°æ®
    print("\n[1/6] Loading data...")
    data_start = time.time()
    trainloader, testloader = get_cifar10_dataloader(
        root=cfg.DATA_ROOT, 
        batch_size=cfg.BATCH_SIZE, 
        num_workers=cfg.NUM_WORKERS
    )
    classes = getattr(trainloader.dataset, 'classes', default_cifar10_classes())
    data_time = time.time() - data_start
    print(f"âœ“ Data loaded in {data_time:.1f}s: {len(trainloader)} train batches, {len(testloader)} test batches")
    
    # åˆ›å»ºæ¨¡å‹
    print("\n[2/6] Building model...")
    model_start = time.time()
    model = get_model(
        activation=exp_cfg['activation'],
        use_dropout=exp_cfg['use_dropout'],
        dropout_rate=cfg.DROPOUT_RATE,
        use_batchnorm=exp_cfg['use_batchnorm'],
        kernel_size=exp_cfg['kernel_size']
    )
    model = model.to(cfg.DEVICE)
    model_time = time.time() - model_start
    print(f"âœ“ Model created in {model_time:.1f}s: {sum(p.numel() for p in model.parameters())/1e6:.2f}M parameters")
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=cfg.LEARNING_RATE, 
                          momentum=cfg.MOMENTUM, weight_decay=cfg.WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.EPOCHS)
    
    # åˆ›å»ºTensorBoardè®°å½•å™¨
    writer = SummaryWriter(log_dir=str(exp_dir / 'logs'))
    
    # è®­ç»ƒå¾ªç¯
    print("\n[3/6] Starting training...")
    train_losses, test_losses = [], []
    train_accs, test_accs = [], []
    best_acc = 0.0
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    for epoch in range(cfg.EPOCHS):
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch(
            model, trainloader, criterion, optimizer, cfg.DEVICE, epoch, writer, 
            use_amp=cfg.USE_MIXED_PRECISION
        )
        
        # æµ‹è¯•
        test_loss, test_acc = test_epoch(
            model, testloader, criterion, cfg.DEVICE, epoch, writer
        )
        
        # è®°å½•ç»“æœ
        train_losses.append(train_loss)
        test_losses.append(test_loss)
        train_accs.append(train_acc)
        test_accs.append(test_acc)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            save_model(model, exp_dir / 'best_model.pth')
        
        # æ‰“å°epochæ€»ç»“
        print(f"Epoch {epoch+1:02d}/{cfg.EPOCHS} | "
              f"Train: {train_acc:.2f}% | Test: {test_acc:.2f}% | "
              f"Best: {best_acc:.2f}%")
    
    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    total_time = time.time() - start_time

    # æŒ‰ç±»åˆ«ç»Ÿè®¡å‡†ç¡®ç‡
    print("\n[4/6] Per-class analysis...")
    per_class_acc, overall_acc = calculate_per_class_accuracy(model, testloader, cfg.DEVICE, classes, save_dir=exp_dir)

    # å¯è§†åŒ–é¢„æµ‹ç»“æœ
    print("\n[5/6] Visualizing predictions...")
    visualize_predictions(model, testloader, cfg.DEVICE, classes, num_samples=16, save_dir=exp_dir)

    # å¯è§†åŒ–è®­ç»ƒæ›²çº¿
    print("\n[6/6] Generating plots...")
    plot_results(train_losses, test_losses, train_accs, test_accs, exp_dir)

    # ä¿å­˜æœ€ç»ˆç»“æœ
    print("\nSaving results...")
    results = {
        "config": exp_cfg,
        "final_train_acc": train_accs[-1],
        "final_test_acc": test_accs[-1],
        "best_test_acc": best_acc,
        "total_time_minutes": total_time / 60,
        "train_losses": train_losses,
        "test_losses": test_losses,
        "train_accs": train_accs,
        "test_accs": test_accs,
        "per_class_accuracy": per_class_acc,
        "overall_test_acc": overall_acc,
        "classes": classes
    }
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    import json
    with open(exp_dir / 'results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # ä¿å­˜ç®€è¦ç»“æœ
    with open(exp_dir / 'summary.txt', 'w') as f:
        f.write(f"Experiment: {exp_name}\n")
        f.write(f"Config: {exp_cfg}\n\n")
        f.write(f"Final Train Accuracy: {train_accs[-1]:.2f}%\n")
        f.write(f"Final Test Accuracy: {test_accs[-1]:.2f}%\n")
        f.write(f"Best Test Accuracy: {best_acc:.2f}%\n")
        f.write(f"Total Training Time: {total_time/60:.2f} minutes\n")
    
    writer.close()
    
    print(f"\nâœ“ Experiment completed in {total_time/60:.2f} minutes!")
    print(f"âœ“ Results saved to: {exp_dir}")
    
    return results

def main():
    cfg = Config()
    
    # åœ¨è¿™é‡Œå¯ç”¨cuDNNä¼˜åŒ–ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        print("ğŸš€ CUDA enabled with cuDNN auto-tuning")
    
    print(f"PyTorch Version: {torch.__version__}")
    print(f"Device: {cfg.DEVICE}")
    print(f"Batch Size: {cfg.BATCH_SIZE}")
    print(f"Workers: {cfg.NUM_WORKERS}")
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(cfg.RESULTS_PATH, exist_ok=True)
    os.makedirs(cfg.MODEL_SAVE_PATH, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡Œæ‰€æœ‰å®éªŒ
    run_all = input("Run all 6 experiments? (y/n, default=y): ").strip().lower() != 'n'
    
    if run_all:
        # è¿è¡Œæ‰€æœ‰å®éªŒ
        all_results = {}
        for exp_name, exp_cfg in cfg.EXPERIMENT_CONFIGS.items():
            try:
                result = run_single_experiment(exp_name, exp_cfg, cfg)
                all_results[exp_name] = result
            except Exception as e:
                print(f"âŒ Error in {exp_name}: {e}")
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        print("\n" + "="*60)
        print("GENERATING FINAL REPORT...")
        print("="*60)
        generate_comparison_report(all_results, cfg.RESULTS_PATH)
    else:
        # åªè¿è¡ŒåŸºå‡†å®éªŒ
        print("Running baseline experiment only...")
        run_single_experiment("Exp1_Baseline_ReLU", cfg.EXPERIMENT_CONFIGS["Exp1_Baseline_ReLU"], cfg)

if __name__ == '__main__':
    main()